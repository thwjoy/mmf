dataset_config:
  masked_sbu:
    data_dir: ${env.data_dir}
    depth_first: false
    fast_read: false
    use_images: false
    use_features: true
    features:
      sbu/dataset/SBU_captioned_photo_dataset_urls.txt  
    annotations:
      sbu/dataset/SBU_captioned_photo_dataset_captions.txt  
    #     train:
    #     -  sbu_captions/detectron_fix_100/fc6/train_val
    #     val:
    #     -  sbu_captions/detectron_fix_100/fc6/train_val
    #     test:
    #     -  sbu_captions/detectron_fix_100/fc6/train_val
    # annotations:
    #     train:
    #     - imdb/sbu_captions/train.npy
    #     val:
    #     - imdb/sbu_captions/val.npy
    #     test:
    #     - imdb/sbu_captions/val.npy
    processors:
      text_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          mask_probability: 0
          max_seq_length: 16
      image_processor:
        type: torchvision_transforms
        params:
          transforms:
            - type: Resize
              params:
                size: [256, 256]
            - type: CenterCrop
              params:
                size: [224, 224]
            - ToTensor
            - GrayScaleTo3Channels
            - type: Normalize
              params:
                mean: [0.46777044, 0.44531429, 0.40661017]
                std: [0.12221994, 0.12145835, 0.14380469]
    return_features_info: false
    # Return OCR information
    use_ocr: false
    # Return spatial information of OCR tokens if present
    use_ocr_info: false
