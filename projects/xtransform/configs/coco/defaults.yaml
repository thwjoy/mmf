# dataset_config:
#   coco:
#     data_dir: ${env.data_dir}/datasets
#     depth_first: false
#     fast_read: false
#     use_images: false
#     use_features: true
#     zoo_requirements:
#     - coco.defaults
#     # annotation_style can be coco or textcaps which allows us to override
#     # the dataset class
#     annotation_style: coco
#     images:
#       train:
#       - coco/defaults/images/train2014
#       val:
#       - coco/defaults/images/val2014
#       test:
#       - coco/defaults/images/test2015
#     # features:
#     #   train:
#     #   - coco/defaults/features/trainval2014.lmdb
#     #   val:
#     #   - coco/defaults/features/trainval2014.lmdb
#     #   test:
#     #   - coco/defaults/features/trainval2014.lmdb
#     annotations:
#       train:
#       - coco/defaults/annotations/imdb_karpathy_train.npy
#       val:
#       - coco/defaults/annotations/imdb_karpathy_val.npy
#       test:
#       - coco/defaults/annotations/imdb_karpathy_test.npy
#     max_features: 100
#     processors:
#       text_processor:
#         type: vocab
#         params:
#           max_length: 52
#           vocab:
#             type: intersected
#             embedding_name: glove.6B.300d
#             vocab_file: coco/defaults/extras/vocabs/vocabulary_captioning_thresh5.txt
#           preprocessor:
#             type: simple_sentence
#             params: {}
#       caption_processor:
#         type: caption
#         params:
#           vocab:
#             type: intersected
#             embedding_name: glove.6B.300d
#             vocab_file: coco/defaults/extras/vocabs/vocabulary_captioning_thresh5.txt
#     min_captions_per_img: 5
#     return_features_info: false
#     # Return OCR information
#     use_ocr: false
#     # Return spatial information of OCR tokens if present
#     use_ocr_info: false

evaluation:
  metrics:
  - type: xgen
    params: 
      save_dir: ${env.save_dir}

model_config:
  xgen:
    losses:
    - cross_transformative_loss
    
training:
  max_updates: 100000
  checkpoint_interval: 4000
  evaluation_interval: 1000
  batch_size: 256 # 32 per GPU * 8 GPU
  log_interval: 1000

optimizer:
  type: adam_w
  params:
    lr: 1e-4
    eps: 1e-8
    weight_decay: 1e-2
